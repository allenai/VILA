{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"unicode-char-categories.csv\")\n",
    "# From https://www.fileformat.info/info/unicode/category/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shannon/anaconda3/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0928 13:51:53.949661 4404223424 filelock.py:274] Lock 140539838121576 acquired on /Users/shannon/.cache/huggingface/transformers/b723c27ef9c2c0dcb14e2579b1c4813399147edc91358c588657f48079bd37c4.0ee3de34eb96674c87647d1bc7197ef5dca8f7ed09679670c5e4fa17a1dce45a.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2409abb7d664823987121a49de34bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0928 13:51:54.105487 4404223424 filelock.py:318] Lock 140539838121576 released on /Users/shannon/.cache/huggingface/transformers/b723c27ef9c2c0dcb14e2579b1c4813399147edc91358c588657f48079bd37c4.0ee3de34eb96674c87647d1bc7197ef5dca8f7ed09679670c5e4fa17a1dce45a.lock\n",
      "I0928 13:51:54.222512 4404223424 filelock.py:274] Lock 140539940190248 acquired on /Users/shannon/.cache/huggingface/transformers/12219894b117ccf78f257f5361cde58cdfabfebc79fee721f8cb0504139179f9.a5784bb4d9b1c181841fc2293cd92bd2778b2284fcc5bd9a91a12c5e5f11fab0.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca41f3c72704deb89fd531ffaa945d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0928 13:51:54.433845 4404223424 filelock.py:318] Lock 140539940190248 released on /Users/shannon/.cache/huggingface/transformers/12219894b117ccf78f257f5361cde58cdfabfebc79fee721f8cb0504139179f9.a5784bb4d9b1c181841fc2293cd92bd2778b2284fcc5bd9a91a12c5e5f11fab0.lock\n",
      "I0928 13:51:54.538693 4404223424 filelock.py:274] Lock 140539940190920 acquired on /Users/shannon/.cache/huggingface/transformers/8b3025e00d8d7a8f3857e0d178c15888924b302167053c7e48af38f837baf20d.906feaed289524cc12e69304a4700cfc05d1f19a278001ef8ec7d3f4c7773c84.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74d7471e8f1497c80be2a9de7606f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0928 13:51:54.829241 4404223424 filelock.py:318] Lock 140539940190920 released on /Users/shannon/.cache/huggingface/transformers/8b3025e00d8d7a8f3857e0d178c15888924b302167053c7e48af38f837baf20d.906feaed289524cc12e69304a4700cfc05d1f19a278001ef8ec7d3f4c7773c84.lock\n",
      "I0928 13:51:55.047997 4404223424 filelock.py:274] Lock 140539912818192 acquired on /Users/shannon/.cache/huggingface/transformers/0a80689755fc45e25c71b1b136f664c8c42622c22fa0d3846105f08182ee040f.4e79c48f578f6c9787d9a5e0b5dee9800ab9f7b5527c343de4b22139b4b950f4.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed3ea79cfb2470ab345155e0a0d21bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0928 13:51:55.200149 4404223424 filelock.py:318] Lock 140539912818192 released on /Users/shannon/.cache/huggingface/transformers/0a80689755fc45e25c71b1b136f664c8c42622c22fa0d3846105f08182ee040f.4e79c48f578f6c9787d9a5e0b5dee9800ab9f7b5527c343de4b22139b4b950f4.lock\n",
      "I0928 13:51:55.311869 4404223424 filelock.py:274] Lock 140539912818192 acquired on /Users/shannon/.cache/huggingface/transformers/e652b8191d15aa872baecf86bee43ca3a9c7051ea1a0ca419a00d97cb6edc3d4.918796645b111451dabe315f42e653b50349145063ecb13ad1e7205cd75dd219.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01baf66eeebf436e93548bc1e60677e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0928 13:51:55.479192 4404223424 filelock.py:318] Lock 140539912818192 released on /Users/shannon/.cache/huggingface/transformers/e652b8191d15aa872baecf86bee43ca3a9c7051ea1a0ca419a00d97cb6edc3d4.918796645b111451dabe315f42e653b50349145063ecb13ad1e7205cd75dd219.lock\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/ivila-row-layoutlm-finetuned-s2vl-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNICODE_CATEGORIES_TO_REPLACE = [\"Cc\", \"Cf\", \"Co\", \"Cs\", \"Mn\", \"Zl\", \"Zp\", \"Zs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tokenization_len(row):    \n",
    "    uni_code = r'\\u' + row['Character'][2:]\n",
    "    s = uni_code.encode().decode('unicode_escape')\n",
    "    return len(tokenizer(s, add_special_tokens=False)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokenization Length'] = df.apply(calculate_tokenization_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cc</th>\n",
       "      <td>65</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cf</th>\n",
       "      <td>163</td>\n",
       "      <td>0.766871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Co</th>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cs</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mn</th>\n",
       "      <td>1950</td>\n",
       "      <td>0.549744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zl</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zp</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zs</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count      mean\n",
       "Code                 \n",
       "Cc       65  0.000000\n",
       "Cf      163  0.766871\n",
       "Co        6  0.666667\n",
       "Cs        6  0.000000\n",
       "Mn     1950  0.549744\n",
       "Zl        1  0.000000\n",
       "Zp        1  0.000000\n",
       "Zs       17  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Code')['Tokenization Length'].agg(['count', 'mean']).loc[UNICODE_CATEGORIES_TO_REPLACE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cc', 'Cf', 'Co', 'Cs', 'Mc', 'Mn', 'So', 'Zl', 'Zp', 'Zs'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Tokenization Length']==0].Code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Tokenization Length']==0]['Character'].to_csv(\"zero-length-unicode-chars.txt\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on All Unicode Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_UNICODE_CHARS = [[chr(i),unicodedata.category(chr(i))] for i in range(sys.maxunicode+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.DataFrame(ALL_UNICODE_CHARS, columns=['Character', 'Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tokenization_len(row):    \n",
    "    return len(tokenizer(row['Character'], add_special_tokens=False)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete['Tokenization Length'] = df_complete.apply(calculate_tokenization_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141318"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_complete[df_complete['Tokenization Length'] == 0]['Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cc</th>\n",
       "      <td>65</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zl</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zp</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cs</th>\n",
       "      <td>2048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zs</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Co</th>\n",
       "      <td>137468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cf</th>\n",
       "      <td>151</td>\n",
       "      <td>0.006623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mn</th>\n",
       "      <td>1690</td>\n",
       "      <td>0.072781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So</th>\n",
       "      <td>5777</td>\n",
       "      <td>0.999827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ll</th>\n",
       "      <td>2063</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sm</th>\n",
       "      <td>948</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sk</th>\n",
       "      <td>121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc</th>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ps</th>\n",
       "      <td>75</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Po</th>\n",
       "      <td>544</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pi</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pf</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pe</th>\n",
       "      <td>73</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pd</th>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>676</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cn</th>\n",
       "      <td>846359</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nd</th>\n",
       "      <td>580</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Me</th>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lu</th>\n",
       "      <td>1702</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lt</th>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lm</th>\n",
       "      <td>249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pc</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nl</th>\n",
       "      <td>236</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mc</th>\n",
       "      <td>394</td>\n",
       "      <td>1.005076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lo</th>\n",
       "      <td>112721</td>\n",
       "      <td>1.024219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count      mean\n",
       "Code                  \n",
       "Cc        65  0.000000\n",
       "Zl         1  0.000000\n",
       "Zp         1  0.000000\n",
       "Cs      2048  0.000000\n",
       "Zs        17  0.000000\n",
       "Co    137468  0.000000\n",
       "Cf       151  0.006623\n",
       "Mn      1690  0.072781\n",
       "So      5777  0.999827\n",
       "Ll      2063  1.000000\n",
       "Sm       948  1.000000\n",
       "Sk       121  1.000000\n",
       "Sc        53  1.000000\n",
       "Ps        75  1.000000\n",
       "Po       544  1.000000\n",
       "Pi        12  1.000000\n",
       "Pf        10  1.000000\n",
       "Pe        73  1.000000\n",
       "Pd        24  1.000000\n",
       "No       676  1.000000\n",
       "Cn    846359  1.000000\n",
       "Nd       580  1.000000\n",
       "Me        13  1.000000\n",
       "Lu      1702  1.000000\n",
       "Lt        31  1.000000\n",
       "Lm       249  1.000000\n",
       "Pc        10  1.000000\n",
       "Nl       236  1.000000\n",
       "Mc       394  1.005076\n",
       "Lo    112721  1.024219"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.groupby('Code')['Tokenization Length'].agg(['count', 'mean']).sort_values('mean', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cc', 'Zs', 'Cf', 'Mn', 'Zl', 'Zp', 'Cs', 'Co', 'So'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete[df_complete['Tokenization Length']==0].Code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Code</th>\n",
       "      <th>Tokenization Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65533</th>\n",
       "      <td>�</td>\n",
       "      <td>So</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Character Code  Tokenization Length\n",
       "65533         �   So                    0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete[(df_complete['Tokenization Length']==0) & (df_complete['Code']=='So')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete[df_complete['Tokenization Length']==0]['Character'].apply(lambda e: ord(e)).to_csv(\"zero-length-unicode-ord.txt\", index=None, header=None,  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141318"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_complete[df_complete['Tokenization Length']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
